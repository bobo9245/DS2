{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 Import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 학습에 사용되는 자잘한 것들\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    \"\"\"\n",
    "    모델 구조 수정 금지.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoding_dim, cat_features, num_features, num_classes, cat_cardinalities):\n",
    "        super(BaseModel, self).__init__()\n",
    "        # cat_cardinalities는 각 범주형 변수의 고유값 개수 리스트\n",
    "        self.cat_embeddings = nn.ModuleList([nn.Embedding(cardinality, 5) for cardinality in cat_cardinalities])\n",
    "        self.fc_cat = nn.Linear(len(cat_features) * 5 + len(num_features), 64)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        # Apply embedding layers\n",
    "        embeddings = [emb(x_cat[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n",
    "        x = torch.cat(embeddings + [x_num], dim=1)\n",
    "        x = self.fc_cat(x)\n",
    "        encoded = self.encoder(x)\n",
    "        out = self.classifier(encoded)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_standardize_data(data, mode):\n",
    "    label_encoders = {}\n",
    "    categorical_columns_train = ['Card Brand', 'Card Type', 'Card Number', 'Expires', 'Acct Open Date', 'Is Fraud?', 'Error Message']\n",
    "    categorical_columns_test = ['Card Brand', 'Card Type', 'Card Number', 'Expires', 'Acct Open Date', 'Error Message']\n",
    "    data['Error Message'] = data['Error Message'].fillna('None')\n",
    "    categorical_columns = categorical_columns_train if mode == 'Train' else categorical_columns_test\n",
    "\n",
    "    cat_cardinalities = []\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        label_encoders[col] = le\n",
    "        cat_cardinalities.append(data[col].nunique())\n",
    "\n",
    "    data['Zipcode'] = (data['Zipcode'] // 100).astype(int)\n",
    "    le_zipcode = LabelEncoder()\n",
    "    data['Zipcode'] = le_zipcode.fit_transform(data['Zipcode'])\n",
    "    cat_cardinalities.append(data['Zipcode'].nunique())\n",
    "\n",
    "    data['Merchandise Code'] = (data['Merchandise Code'] // 100).astype(int)\n",
    "    le_merchandise_code = LabelEncoder()\n",
    "    data['Merchandise Code'] = le_merchandise_code.fit_transform(data['Merchandise Code'])\n",
    "    cat_cardinalities.append(data['Merchandise Code'].nunique())\n",
    "\n",
    "    data['Has Chip'] = np.where(data['Has Chip'] == True, 1, 0)\n",
    "    cat_cardinalities.append(data['Has Chip'].nunique())\n",
    "\n",
    "    data['Birth Year'] = data['Birth Year'] - data['Birth Year'].min()\n",
    "    data['Year PIN last Changed'] = data['Year PIN last Changed'] - data['Year PIN last Changed'].min()\n",
    "\n",
    "    # Continuous columns for StandardScaler\n",
    "    continuous_columns = [\n",
    "        'Current Age', 'Retirement Age', 'Birth Year', 'Birth Month', 'Per Capita Income - Zipcode',\n",
    "        'Yearly Income', 'Total Debt', 'Credit Score', 'Credit Limit', 'Year', 'Month', 'Day', 'Amount'\n",
    "    ]\n",
    "    scaler = StandardScaler()\n",
    "    data[continuous_columns] = scaler.fit_transform(data[continuous_columns])\n",
    "\n",
    "    # Identify categorical and numerical features\n",
    "    categorical_columns += ['Zipcode', 'Merchandise Code', 'Has Chip']\n",
    "    cat_features = data[categorical_columns].astype(int)  # Ensure categorical features are integer\n",
    "    num_features = data[continuous_columns]\n",
    "\n",
    "    return cat_features, num_features, cat_cardinalities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Card Brand  Card Type  Card Number  Expires  Acct Open Date  \\\n",
      "0                 2          1         3088       57             203   \n",
      "1                 2          1         3088       57             203   \n",
      "2                 2          1         3088       57             203   \n",
      "3                 2          1         3088       57             203   \n",
      "4                 2          1         3088       57             203   \n",
      "...             ...        ...          ...      ...             ...   \n",
      "1698413           2          0         2159       55             120   \n",
      "1698414           2          0         2159       55             120   \n",
      "1698415           2          0         2159       55             120   \n",
      "1698416           2          0         2159       55             120   \n",
      "1698417           2          0         2159       55             120   \n",
      "\n",
      "         Error Message  Zipcode  Merchandise Code  Has Chip  \n",
      "0                   18       52                20         1  \n",
      "1                   20       52                24         1  \n",
      "2                   20       52                30         1  \n",
      "3                   20       52                20         1  \n",
      "4                   20       52                19         1  \n",
      "...                ...      ...               ...       ...  \n",
      "1698413             20      540                30         1  \n",
      "1698414             20      540                20         1  \n",
      "1698415             20      540                22         1  \n",
      "1698416             20      540                 9         1  \n",
      "1698417             20      540                 9         1  \n",
      "\n",
      "[1698418 rows x 9 columns]          Current Age  Retirement Age  Birth Year  Birth Month  \\\n",
      "0           0.055478       -0.105149   -0.066665     1.248646   \n",
      "1           0.055478       -0.105149   -0.066665     1.248646   \n",
      "2           0.055478       -0.105149   -0.066665     1.248646   \n",
      "3           0.055478       -0.105149   -0.066665     1.248646   \n",
      "4           0.055478       -0.105149   -0.066665     1.248646   \n",
      "...              ...             ...         ...          ...   \n",
      "1698413    -1.902275       -1.789037    1.892100     1.248646   \n",
      "1698414    -1.902275       -1.789037    1.892100     1.248646   \n",
      "1698415    -1.902275       -1.789037    1.892100     1.248646   \n",
      "1698416    -1.902275       -1.789037    1.892100     1.248646   \n",
      "1698417    -1.902275       -1.789037    1.892100     1.248646   \n",
      "\n",
      "         Per Capita Income - Zipcode  Yearly Income  Total Debt  Credit Score  \\\n",
      "0                           0.458919       1.550286    1.607348      0.694038   \n",
      "1                           0.458919       1.550286    1.607348      0.694038   \n",
      "2                           0.458919       1.550286    1.607348      0.694038   \n",
      "3                           0.458919       1.550286    1.607348      0.694038   \n",
      "4                           0.458919       1.550286    1.607348      0.694038   \n",
      "...                              ...            ...         ...           ...   \n",
      "1698413                     0.721289       1.120938    1.405477      0.132863   \n",
      "1698414                     0.721289       1.120938    1.405477      0.132863   \n",
      "1698415                     0.721289       1.120938    1.405477      0.132863   \n",
      "1698416                     0.721289       1.120938    1.405477      0.132863   \n",
      "1698417                     0.721289       1.120938    1.405477      0.132863   \n",
      "\n",
      "         Credit Limit  Year     Month       Day    Amount  \n",
      "0            0.744991   0.0 -1.611192 -1.218515  1.346058  \n",
      "1            0.744991   0.0 -1.611192 -1.104823  0.189164  \n",
      "2            0.744991   0.0 -1.611192 -0.763746  0.685237  \n",
      "3            0.744991   0.0 -1.611192 -0.536362 -0.283112  \n",
      "4            0.744991   0.0 -1.611192 -0.422669  1.130055  \n",
      "...               ...   ...       ...       ...       ...  \n",
      "1698413     -0.082780   0.0  1.580670  1.623790  0.893917  \n",
      "1698414     -0.082780   0.0  1.580670  1.623790  0.282521  \n",
      "1698415     -0.082780   0.0  1.580670  1.623790  0.121435  \n",
      "1698416     -0.082780   0.0  1.580670  1.623790  0.132418  \n",
      "1698417     -0.082780   0.0  1.580670  1.737482 -0.153145  \n",
      "\n",
      "[1698418 rows x 13 columns] [3, 3, 3850, 60, 297, 22, 555, 37, 2]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "x_cat_train, x_num_train, cat_cardinalities_train = encode_and_standardize_data(train_data, mode='Train')\n",
    "x_cat_test, x_num_test, cat_cardinalities_test = encode_and_standardize_data(test_data, mode='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card Brand             2\n",
      "Card Type              1\n",
      "Card Number         3088\n",
      "Expires               57\n",
      "Acct Open Date       203\n",
      "Error Message         20\n",
      "Zipcode               52\n",
      "Merchandise Code      24\n",
      "Has Chip               1\n",
      "Name: 1, dtype: int32\n",
      "Current Age                    0.055478\n",
      "Retirement Age                -0.105149\n",
      "Birth Year                    -0.066665\n",
      "Birth Month                    1.248646\n",
      "Per Capita Income - Zipcode    0.458919\n",
      "Yearly Income                  1.550286\n",
      "Total Debt                     1.607348\n",
      "Credit Score                   0.694038\n",
      "Credit Limit                   0.744991\n",
      "Year                           0.000000\n",
      "Month                         -1.611192\n",
      "Day                           -1.104823\n",
      "Amount                         0.189164\n",
      "Name: 1, dtype: float64\n",
      "[3, 3, 3850, 60, 297, 22, 555, 37, 2]\n"
     ]
    }
   ],
   "source": [
    "print(x_cat_test.iloc[1], x_num_test.iloc[1], cat_cardinalities_test,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch tensor로 변환\n",
    "x_cat_train_tensor = torch.tensor(x_cat_train.values, dtype=torch.long)  # 정수형\n",
    "x_num_train_tensor = torch.tensor(x_num_train.values, dtype=torch.float32)  # 실수형\n",
    "\n",
    "x_cat_test_tensor = torch.tensor(x_cat_test.values, dtype=torch.long)\n",
    "x_num_test_tensor = torch.tensor(x_num_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1644768x32 and 64x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m BaseModel(encoding_dim\u001b[38;5;241m=\u001b[39mencoding_dim, cat_features\u001b[38;5;241m=\u001b[39mx_cat_train\u001b[38;5;241m.\u001b[39mcolumns, num_features\u001b[38;5;241m=\u001b[39mx_num_train\u001b[38;5;241m.\u001b[39mcolumns, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, cat_cardinalities\u001b[38;5;241m=\u001b[39mcat_cardinalities_train)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 모델 출력 테스트\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_num_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[70], line 35\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x_cat, x_num)\u001b[0m\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_cat(x)\n\u001b[0;32m     34\u001b[0m encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m---> 35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1644768x32 and 64x32)"
     ]
    }
   ],
   "source": [
    "num_classes = 2  # 예: Is Fraud? 이진 분류\n",
    "encoding_dim = 32\n",
    "\n",
    "model = BaseModel(encoding_dim=encoding_dim, cat_features=x_cat_train.columns, num_features=x_num_train.columns, num_classes=num_classes, cat_cardinalities=cat_cardinalities_train)\n",
    "\n",
    "# 모델 출력 테스트\n",
    "output = model(x_cat_train_tensor, x_num_train_tensor)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
